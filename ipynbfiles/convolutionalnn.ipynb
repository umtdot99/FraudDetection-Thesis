{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bf83de9-5773-45fe-ab40-e03c34c65a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7c0bafb-16c7-40ba-9471-36a0893be413",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionNN(nn.Module):\n",
    "    \"\"\" \n",
    "        Class to initiate the Convolutional Neural Network object. \n",
    "\n",
    "        Args: \n",
    "            input_dimension (int) : Size of input dimension\n",
    "            output_dimension (int) : Size of output dimension\n",
    "            kernel (int) : Size of the kernel.\n",
    "            padding (int) : Size of the padding.\n",
    "            dropout_rate (float): Size of the drop out rate.\n",
    "            layer_list (list[int]): List that includes the layers of the convolutional network.\n",
    "            dropout_list (list[float]): List of drop out rates. \n",
    "            pool (list[int]): List of pool with numbers. \n",
    "            layer_count (int): Desired number of layers in the structure.\n",
    "            activations (list[str]) : List of activation functions.\n",
    "            default_layer (int): Dimension of the layer default. \n",
    "            linear_layer (int): Dimension of the linear layer.\n",
    "            flattened_size (int): Size of the flattening.\n",
    "            loss_method (str) : Loss method to evaluate training and testing. \n",
    "            opt_method (str): Optimization method. \n",
    "            lr (float): Learning rate. \n",
    "            class_weights (dict[int]: float): Class weights for imbalance handling. \n",
    "            epochs (int): Number of epochs. \n",
    "            threshold (float): Threshold level for predictions\n",
    "            \n",
    "    \"\"\"\n",
    "    def __init__(self, loss_method = \"BCE\", opt_method = \"SGD\", lr = 0.01,\n",
    "                 threshold = 0.3, class_weights = None, epochs=5, input_dimension = None, dropout_list=None, linear_act = None, flattened_size = None, linear_layer = None, \n",
    "                 layer_list = None,default_layer=None, pool=None, activations=None, layer_count = None, dropout_rate= None, output_dimension= None, kernel = 3, padding=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_dimension = input_dimension\n",
    "        self.output_dimension = output_dimension\n",
    "        self.kernel = kernel\n",
    "        self.padding = padding\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.layer_list = layer_list\n",
    "        self.dropout_list = dropout_list\n",
    "        self.pool = pool\n",
    "        self.layer_count = layer_count\n",
    "        self.activations = activations\n",
    "        self.default_layer = default_layer\n",
    "        self.linear_layer = linear_layer\n",
    "        self.flattened_size = flattened_size\n",
    "        self.loss_method = loss_method\n",
    "        self.opt_method = opt_method\n",
    "        self.lr = lr \n",
    "        self.class_weights = class_weights\n",
    "        self.epochs = epochs\n",
    "        self.threshold = threshold\n",
    "        \n",
    "        if self.class_weights is not None:\n",
    "            self.class_weights = torch.tensor([class_weights[1], class_weights[0]], dtype= torch.float32)\n",
    "        else: \n",
    "            self.class_weights = class_weights\n",
    "            \n",
    "        layer_dict = {}\n",
    "        \n",
    "        if self.layer_list is None: \n",
    "            \n",
    "            layer = [self.input_dimension] + [self.default_layer]*self.layer_count + [self.output_dimension]\n",
    "\n",
    "        else: \n",
    "            \n",
    "            layer = self.layer_list\n",
    "\n",
    "        for i in range(1, len(layer)):\n",
    "\n",
    "            layer_dict[f\"conv{i}\"] = nn.Conv1d(layer[i-1], layer[i], kernel_size = self.kernel, padding = self.padding)\n",
    "\n",
    "            act = None\n",
    "            if self.activations is None:\n",
    "                \n",
    "                layer_dict[f\"act{i-1}\"] = nn.ReLU()\n",
    "\n",
    "            else: \n",
    "\n",
    "                if len(self.activations) < (len(layer)):\n",
    "                    need_act = (len(layer)) - len(self.activations)\n",
    "                    act = self.activations + [\"identity\"]*need_act \n",
    "                    \n",
    "                layer_dict[f\"act{i-1}\"] = self.get_activation(act[i-1])\n",
    "\n",
    "            pooling = None            \n",
    "            if self.pool is None:\n",
    "                \n",
    "                layer_dict[f\"pooling{i-1}\"] = nn.MaxPool1d(2,2)\n",
    "\n",
    "            else: \n",
    "                \n",
    "                if len(self.pool) < (len(layer)):\n",
    "                    need_pool = (len(layer)) - len(self.pool)\n",
    "                    pooling = self.pool + [2]*need_pool\n",
    "                layer_dict[f\"pooling{i-1}\"] = nn.MaxPool1d(pooling[i-1], pooling[i])\n",
    "\n",
    "            drop = None\n",
    "            if self.dropout_list is None: \n",
    "                \n",
    "                layer_dict[f\"dropout{i-1}\"] = nn.Dropout(self.dropout_rate)\n",
    "\n",
    "            else: \n",
    "                if len(self.dropout_list) < (len(layer)):\n",
    "                    need_drop = (len(layer)) - len(self.dropout_list)\n",
    "                    drop = self.dropout_list + [0.3]*need_drop \n",
    "                layer_dict[f\"dropout{i-1}\"] = nn.Dropout(drop[i-1])\n",
    "\n",
    "    \n",
    "        \n",
    "        self.linear1 = nn.Linear(self.flattened_size, self.linear_layer)\n",
    "        self.linear2 = nn.Linear(self.linear_layer, self.output_dimension)\n",
    "\n",
    "        self.process = nn.ModuleDict(layer_dict)\n",
    "        print(self.process)\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\" \n",
    "        Forward method to initate the transformation of the input to output.\n",
    "        \n",
    "            Parameters: \n",
    "                x (tensor) : Training tensor for x. \n",
    "        \n",
    "            Returns: \n",
    "                Returns the processed version of the input.\n",
    "        \"\"\"\n",
    "        for m in self.process.values():\n",
    "            x = m(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        \n",
    "        print(x)\n",
    "        return x\n",
    "        \n",
    "    def get_activation(self, activation_):\n",
    "        \"\"\" \n",
    "            Method to select the activation function.\n",
    "\n",
    "            Parameters: \n",
    "                activation_ (str): Name of the activation function as a string.\n",
    "\n",
    "            Returns: \n",
    "                Returns the activation function with nn module. \n",
    "\n",
    "        \"\"\"\n",
    "        if activation_ == \"relu\": \n",
    "            return nn.ReLU()\n",
    "\n",
    "        elif activation_ == \"tanh\": \n",
    "            return nn.Tanh()\n",
    "\n",
    "        elif activation_ == \"identity\": \n",
    "            return nn.Identity()\n",
    "\n",
    "    def get_loss(self):\n",
    "        \n",
    "        \"\"\" \n",
    "            Method to select the loss function.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.loss_method == \"BCE\":\n",
    "            return nn.BCELoss()\n",
    "        \n",
    "        elif self.loss_method == \"L1\":\n",
    "            return nn.L1Loss()\n",
    "        \n",
    "        elif self.loss_method == \"MSE\":\n",
    "            return nn.MSELoss()\n",
    "\n",
    "        elif self.loss_method == \"CE\":\n",
    "            return nn.CrossEntropyLoss(weight = self.class_weights)\n",
    "\n",
    "        elif self.loss_method == \"BCEwLogit\":\n",
    "            if self.class_weights is not None:\n",
    "                pos_weight = torch.tensor([self.class_weights[1] / self.class_weights[0]])\n",
    "                return nn.BCEWithLogitsLoss(pos_weight = pos_weight)\n",
    "            else: \n",
    "                return nn.BCEWithLogitsLoss()\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"{self.loss_method} is not valid!\")\n",
    "\n",
    "    def get_optimizer(self):\n",
    "        \"\"\" \n",
    "            Method to select the optimization method.\n",
    "\n",
    "        \"\"\"\n",
    "        if self.opt_method == \"SGD\":\n",
    "            return torch.optim.SGD(params = self.parameters(), lr = self.lr)\n",
    "\n",
    "        elif self.opt_method == \"Adam\":\n",
    "            return torch.optim.Adam(params = self.parameters(), lr = self.lr)\n",
    "\n",
    "        elif self.opt_method == \"RMSprop\":\n",
    "            return torch.optim.RMSprop(params = self.parameters(), lr = self.lr)\n",
    "\n",
    "        else: \n",
    "            raise ValueError(f\"{self.opt_method} is not valid!\")\n",
    "\n",
    "    def train_model(self, train_loader, val_loader):\n",
    "        \"\"\" \n",
    "            Training phase of the CNN.\n",
    "\n",
    "            Parameters: \n",
    "                train_loader (tensor) : Training data loader for training.\n",
    "                val_loader (tensor) : Validation data loader for validation.\n",
    "\n",
    "            Returns: \n",
    "                Returns the training and validation loss. \n",
    "        \"\"\"\n",
    "        loss_fn = self.get_loss()\n",
    "        optimizer = self.get_optimizer()        \n",
    "        size = len(train_loader.dataset)\n",
    "        t_loss=[]\n",
    "        val_loss = []\n",
    "        for e in range(self.epochs):\n",
    "            self.train()\n",
    "            train_loss = 0\n",
    "            for batch, (X, y) in enumerate(train_loader):\n",
    "                X = X.unsqueeze(1)\n",
    "                y_logits = self(X).squeeze()\n",
    "                \n",
    "                loss = loss_fn(y_logits, y)\n",
    "    \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    \n",
    "                train_loss += loss.item() * X.size(0)\n",
    "        \n",
    "            train_loss_ = train_loss/len(train_loader.dataset) \n",
    "            t_loss.append(train_loss_)\n",
    "\n",
    "            self.eval()\n",
    "            test_loss = 0\n",
    "            with torch.inference_mode():\n",
    "                for X, y in val_loader: \n",
    "                    \n",
    "                    X = X.unsqueeze(1)\n",
    "                    y_logits = self(X).squeeze()\n",
    "                    test_loss += loss_fn(y_logits, y).item() * y.size(0)\n",
    "                \n",
    "        \n",
    "            test_loss_ = test_loss/len(val_loader.dataset)\n",
    "            val_loss.append(test_loss_)\n",
    "            print(f\"Test loss: {val_loss}\")\n",
    "           \n",
    "        return t_loss, val_loss\n",
    "\n",
    "    def analysis(self, l1, l2):\n",
    "        \"\"\" \n",
    "            Analysis of the auto encoder.\n",
    "\n",
    "            Parameters: \n",
    "                l1 (list) : List of training error.\n",
    "                l2 (list) : List of validation error.\n",
    "                \n",
    "\n",
    "            Returns: \n",
    "                Returns a graph that includes validation and training error in epochs. \n",
    "        \"\"\"\n",
    "        l1_arr = np.array(l1)\n",
    "        l2_arr = np.array(l2)\n",
    "\n",
    "        epoch_l = [i for i in range(1, self.epochs + 1)]\n",
    "        epoch_arr = np.array(epoch_l)\n",
    "\n",
    "        sns.lineplot(x = epoch_arr, y = np.log(l1_arr), label=\"Train Error\")\n",
    "        sns.lineplot(x = epoch_arr, y = np.log(l2_arr), label=\"Valid Error\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def predict(self, test):\n",
    "        \"\"\" \n",
    "            Prediction with CNN.\n",
    "\n",
    "            Parameters: \n",
    "                test (tensor): Test loader for prediction. \n",
    "                \n",
    "\n",
    "            Returns: \n",
    "                Returns probabilities, predictions and labels. \n",
    "        \"\"\"\n",
    "        predictions=[]\n",
    "        labels = []\n",
    "        probs=[]\n",
    "        if self.loss_method == \"BCE\": \n",
    "            \n",
    "            self.eval()\n",
    "            with torch.inference_mode():\n",
    "                for X, y in test:\n",
    "                    X = X.unsqueeze(1)\n",
    "                    output = self(X).squeeze()\n",
    "                    preds = (output > self.threshold).int()\n",
    "                    predictions.append(preds)\n",
    "                    labels.append(y)\n",
    "                    probs.append(output)\n",
    "                    \n",
    "        elif self.loss_method == \"CE\": \n",
    "            self.eval()\n",
    "            with torch.inference_mode():\n",
    "                for X, y in test:\n",
    "                    X = X.unsqueeze(1)\n",
    "                    output = self(X)\n",
    "                    prob = torch.argmax(output, dim=1)\n",
    "                    preds = (prob>self.threshold).int()\n",
    "                    predictions.append(preds)\n",
    "                    labels.append(y)\n",
    "                    probs.append(prob)\n",
    "                    \n",
    "        else:\n",
    "            self.eval()\n",
    "            with torch.inference_mode():\n",
    "                for X, y in test:\n",
    "                    X = X.unsqueeze(1)\n",
    "                    output = self(X).squeeze()\n",
    "                    prob = torch.sigmoid(output)\n",
    "                    preds = (prob > self.threshold).int()\n",
    "                    predictions.append(preds)\n",
    "                    labels.append(y)\n",
    "                    probs.append(prob)\n",
    "\n",
    "        all_preds = torch.cat(predictions).ravel()\n",
    "        all_labels = torch.cat(labels).ravel()\n",
    "        all_probs = torch.cat(probs).ravel()\n",
    "        \n",
    "        return all_probs, all_preds, all_labels\n",
    "        \n",
    "    def report(self, test, pred, labels): \n",
    "        \"\"\" \n",
    "            Reporting part for CNN.\n",
    "\n",
    "            Parameters: \n",
    "                test (tensor): Test loader for prediction.\n",
    "                pred (tensor): Tensor for predictions.\n",
    "                labels (tensor): True labels.\n",
    "                \n",
    "\n",
    "            Returns: \n",
    "                Returns a confusion matrix. \n",
    "        \"\"\"\n",
    "        all_probs, all_preds, all_labels = self.predict(test)\n",
    "        all_probs_arr = all_probs.detach().numpy().ravel()\n",
    "        all_preds_arr = all_preds.detach().numpy().ravel()\n",
    "        all_labels_arr = all_labels.detach().numpy().ravel()\n",
    "        \n",
    "        cm = confusion_matrix(all_labels_arr, all_preds_arr)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.ylabel(\"Actual Class\")\n",
    "        plt.xlabel(\"Predicted Class\")\n",
    "\n",
    "        plt.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61d0c0c-8146-424b-80bb-f83296e182da",
   "metadata": {},
   "source": [
    "##Â References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48fb9b1-16f2-42e1-a1b1-176c05688513",
   "metadata": {},
   "source": [
    "1- GeeksforGeeks. *How to implement neural networks in PyTorch*. Accessed March 12, 2025, from https://www.geeksforgeeks.org/how-to-implement-neural-networks-in-pytorch/\n",
    "\n",
    "2- CodeSignal. *Making predictions with a trained PyTorch model*. Accessed February 10, 2025, from  https://codesignal.com/learn/courses/building-a-neural-network-in-pytorch/lessons/makingpredictions-with-a-trained-pytorch-model\n",
    "\n",
    "3- PyTorch Discuss. *How to make PyTorch model predict* Accessed February 10, 2025, from https://discuss.pytorch.org/t/how-to-make-pytorch-model-predict/167950\n",
    "\n",
    "4- Pytorch Documentation. *torch.nn.Conv1d* - Accessed on March 14, 2025 from https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv1d.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env)",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
